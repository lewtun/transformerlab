{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transformers v4.1.1 and datasets v1.2.1\n",
      "Running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from pprint import pprint\n",
    "from time import perf_counter\n",
    "\n",
    "import sys\n",
    "sys.path.append('../nn_pruning')\n",
    "from nn_pruning.sparse_trainer import SparseTrainer\n",
    "from nn_pruning.sparse_xp import SparseXP\n",
    "from nn_pruning.patch_coordinator import SparseTrainingArguments\n",
    "from nn_pruning.examples.xp import XP, DataTrainingArguments, ModelArguments, XPTrainingArguments, XPTrainer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import transformers\n",
    "datasets.logging.set_verbosity_error()\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using transformers v{transformers.__version__} and datasets v{datasets.__version__}\")\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 9427\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 3270\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 3245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolq = load_dataset(\"super_glue\", \"boolq\")\n",
    "boolq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolq.rename_column_(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 9426,\n",
       " 'labels': 0,\n",
       " 'passage': \"Margin of error -- The margin of error is usually defined as the ``radius'' (or half the width) of a confidence interval for a particular statistic from a survey. One example is the percent of people who prefer product A versus product B. When a single, global margin of error is reported for a survey, it refers to the maximum margin of error for all reported percentages using the full sample from the survey. If the statistic is a percentage, this maximum margin of error can be calculated as the radius of the confidence interval for a reported percentage of 50%.\",\n",
       " 'question': 'is margin of error the same as confidence interval'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolq['train'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_ckpt = \"lewtun/bert-base-uncased-finetuned-boolq\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_ckpt)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(bert_ckpt).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_latency(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    question=\"is margin of error the same as confidence interval\",\n",
    "    passage=\"Margin of error -- The margin of error is usually defined as the ``radius'' (or half the width) of a confidence interval for a particular statistic from a survey. One example is the percent of people who prefer product A versus product B. When a single, global margin of error is reported for a survey, it refers to the maximum margin of error for all reported percentages using the full sample from the survey. If the statistic is a percentage, this maximum margin of error can be calculated as the radius of the confidence interval for a reported percentage of 50%.\"\n",
    "):\n",
    "    inputs = tokenizer(question, passage, truncation=\"only_second\", return_tensors='pt')\n",
    "    latencies = []\n",
    "    # Warmup\n",
    "    for _ in range(10):\n",
    "        _ = model(**inputs)\n",
    "    # Timed run\n",
    "    for _ in range(100):\n",
    "        start_time = perf_counter()\n",
    "        _ = model(**inputs)\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    # Compute run statistics\n",
    "    time_avg_ms = 1000 * np.mean(latencies)\n",
    "    time_std_ms = 1000 * np.std(latencies)\n",
    "    print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
    "    return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency (ms) - 441.52 +\\- 81.77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time_avg_ms': 441.52082815766335, 'time_std_ms': 81.7672099126243}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_latency(bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_ckpt = \"bert-base-uncased\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(x, tokenizer): \n",
    "    return tokenizer(x['question'], x['passage'], truncation=\"only_second\")\n",
    "\n",
    "boolq_enc = boolq.map(tokenize_and_encode, fn_kwargs={'tokenizer' : bert_tokenizer}, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = load_metric('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy_score.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pruning Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use question-answering as template:\n",
    "\n",
    "```python\n",
    "import nn_pruning.examples.question_answering.qa_sparse_xp as qa_sparse_xp\n",
    "\n",
    "qa = qa_sparse_xp.QASparseXP(param_dict)\n",
    "qa.run()\n",
    "```\n",
    "\n",
    "So we need something equivalent to `QASparseXP`. \n",
    "\n",
    "> The question is - what does \"XP\" stand for and do we really need `SparseXP` to do movement-pruning or is this something special needed for collecting metrics etc?\n",
    "\n",
    "Now `QASparseXP` looks like\n",
    "\n",
    "```python\n",
    "class QASparseXP(SparseXP, QAXP):\n",
    "    ARGUMENTS = {\n",
    "        \"model\": ModelArguments,\n",
    "        \"data\": QADataTrainingArguments,\n",
    "        \"training\": XPTrainingArguments,\n",
    "        \"sparse\": SparseTrainingArguments,\n",
    "    }\n",
    "    QA_TRAINER_CLASS = QASparseTrainer\n",
    "    SHORT_NAMER = SparseQAShortNamer\n",
    "    CONSTRUCTOR = AutoModelForQuestionAnswering\n",
    "    LOGIT_NAMES = [\"start_logits\", \"end_logits\"]\n",
    "\n",
    "    def __init__(self, params):\n",
    "        QAXP.__init__(self, params)\n",
    "        SparseXP.__init__(self)\n",
    "\n",
    "    def create_trainer(self, *args, **kwargs):\n",
    "        super().create_trainer(*args, **kwargs)\n",
    "        SparseXP.setup_trainer(self)\n",
    "\n",
    "    @classmethod\n",
    "    def final_finetune(cls, src_path, dest_path, teacher):\n",
    "        param_dict = {\n",
    "            \"model_name_or_path\": src_path,\n",
    "            \"dataset_name\": \"squad\",\n",
    "            \"do_train\": 1,\n",
    "            \"do_eval\": 1,\n",
    "            \"per_device_train_batch_size\": 16,\n",
    "            \"per_device_eval_batch_size\": 128,\n",
    "            \"max_seq_length\": 384,\n",
    "            \"doc_stride\": 128,\n",
    "            \"num_train_epochs\": 10,\n",
    "            \"logging_steps\": 250,\n",
    "            \"save_steps\": 2500,\n",
    "            \"eval_steps\": 2500,\n",
    "            \"save_total_limit\": 50,\n",
    "            \"seed\": 17,\n",
    "            \"evaluation_strategy\": \"steps\",\n",
    "            \"learning_rate\": 3e-5,\n",
    "            \"output_dir\": dest_path,\n",
    "            \"logging_dir\": dest_path,\n",
    "            \"overwrite_cache\": 0,\n",
    "            \"overwrite_output_dir\": 1,\n",
    "            \"warmup_steps\": 10,\n",
    "            \"initial_warmup\": 0,\n",
    "            \"final_warmup\": 0,\n",
    "            \"regularization\": \"\",\n",
    "            \"regularization_final_lambda\": 0,\n",
    "            \"distil_teacher_name_or_path\": teacher,\n",
    "            \"distil_alpha_ce\": 0.1,\n",
    "            \"distil_alpha_teacher\": 0.9,\n",
    "            \"final_finetune\": 1,\n",
    "            \"attention_output_with_dense\": 0,\n",
    "        }\n",
    "\n",
    "        qa = cls(param_dict)\n",
    "        qa.run()\n",
    "\n",
    "        cls.fix_last_checkpoint_bug(dest_path)\n",
    "```\n",
    "\n",
    "so this suggests we also need equivalents of:\n",
    "\n",
    "* `QAXP`\n",
    "* `QADataTrainingArguments`\n",
    "* `XPTrainingArguments`\n",
    "* `QASparseTrainer`\n",
    "* `SparseQAShortNamer`\n",
    "\n",
    "`QAXP` is a subclass of `XP` with much of the pre- and post-processing functions needed for QA:\n",
    "\n",
    "```python\n",
    "class QAXP(XP):\n",
    "    ARGUMENTS = {\n",
    "        \"model\": ModelArguments,\n",
    "        \"data\": QADataTrainingArguments,\n",
    "        \"training\": XPTrainingArguments,\n",
    "    }\n",
    "    QA_TRAINER_CLASS = QATrainer\n",
    "    SHORT_NAMER = TrialShortNamer\n",
    "\n",
    "    @classmethod\n",
    "    def _model_init(self, model_args, model_config):\n",
    "        model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "            model_args.model_name_or_path,\n",
    "            from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "            config=model_config,\n",
    "            cache_dir=model_args.cache_dir,\n",
    "        )\n",
    "        return model\n",
    "    ...\n",
    "```\n",
    "\n",
    "Some remarks:\n",
    "\n",
    "* `XP` is a base class with a lot of methods like `create_trainer` which need implementing in the subclass like `QAXP`\n",
    "* `XPTrainingArguments` is just a subclass of `TrainingArguments`\n",
    "* `QADataTrainingArguments` is a subclass of `DataTrainingArguments` where the latter controls QA pre- and post-processing args\n",
    "* `QASparseTrainer`is a mixin:\n",
    "\n",
    "    ```python\n",
    "    class QASparseTrainer(SparseTrainer, QATrainer):\n",
    "        def __init__(self, sparse_args, *args, **kwargs):\n",
    "            QATrainer.__init__(self, *args, **kwargs)\n",
    "            SparseTrainer.__init__(self, sparse_args)\n",
    "    ```\n",
    "    \n",
    "    \n",
    "* `SparseQAShortNamer` is a subclass of `TrialShortNamer` and seems to just collect hyperparameters, presumably for Optuna search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparseXP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyXP(XP):\n",
    "#     ARGUMENTS = {\n",
    "#         \"model\": ModelArguments,\n",
    "#         \"data\": GlueDataTrainingArguments,\n",
    "#         \"training\": XPTrainingArguments,\n",
    "#     }\n",
    "    MY_TRAINER_CLASS = Trainer\n",
    "#     SHORT_NAMER = TrialShortNamer\n",
    "\n",
    "    @classmethod\n",
    "    def _model_init(cls, model_args, model_config):\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_args.model_name_or_path,\n",
    "            config=model_config,\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(SparseTrainer, Trainer):\n",
    "    def __init__(self, sparse_args, *args, **kwargs):\n",
    "        Trainer.__init__(self, *args, **kwargs)\n",
    "        SparseTrainer.__init__(self, sparse_args)\n",
    "        \n",
    "    def compute_loss(self, model, inputs):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Save past state if it exists\n",
    "        # TODO: this needs to be fixed and made cleaner later.\n",
    "        if self.args.past_index >= 0:\n",
    "            self._past = outputs[self.args.past_index]\n",
    "\n",
    "        # We don't use .loss here since the model may return tuples instead of ModelOutput.\n",
    "        loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "#         print(\"loss\", loss)\n",
    "\n",
    "        self.metrics[\"ce_loss\"] += float(loss)\n",
    "#         loss, distil_loss = self.patch_coordinator.distil_loss_combine(loss, inputs, outputs)\n",
    "#         self.metrics[\"distil_loss\"] += float(distil_loss)\n",
    "#         regu_loss, lamb, info = self.patch_coordinator.regularization_loss(model)\n",
    "\n",
    "#         for kind, values in info.items():\n",
    "#             if kind == \"total\":\n",
    "#                 suffix = \"\"\n",
    "#             else:\n",
    "#                 suffix = \"_\" + kind\n",
    "\n",
    "#             for k, v in values.items():\n",
    "#                 self.metrics[k + suffix] += float(v)\n",
    "\n",
    "        self.loss_counter += 1\n",
    "\n",
    "#         loss = loss + regu_loss * lamb\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTrainingArguments(mask_scores_learning_rate=0.01, dense_pruning_method='topK', attention_pruning_method='topK', ampere_pruning_method='disabled', attention_output_with_dense=True, bias_mask=True, mask_init='constant', mask_scale=0.0, dense_block_rows=1, dense_block_cols=1, attention_block_rows=1, attention_block_cols=1, initial_threshold=1.0, final_threshold=0.5, initial_warmup=1, final_warmup=2, initial_ampere_temperature=0.0, final_ampere_temperature=20.0, regularization='disabled', regularization_final_lambda=0.0, attention_lambda=1.0, dense_lambda=1.0, distil_teacher_name_or_path=None, distil_alpha_ce=0.5, distil_alpha_teacher=0.5, distil_temperature=2.0, final_finetune=False, layer_norm_patch=False, gelu_patch=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_args = SparseTrainingArguments()\n",
    "\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(bert_ckpt).to(device)\n",
    "\n",
    "batch_size = 4\n",
    "learning_rate = 2e-5\n",
    "num_train_epochs = 3\n",
    "logging_steps = len(boolq_enc['train']) // batch_size\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='checkpoints',\n",
    "    evaluation_strategy='epoch',\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=logging_steps,\n",
    "    disable_tqdm=False,\n",
    "#     report_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_pruning.patch_coordinator import ModelPatchingCoordinator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpc = ModelPatchingCoordinator(sparse_args, device, \"checkpoints\", \"logits\", AutoModelForSequenceClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MyTrainer(\n",
    "    sparse_args=sparse_args,\n",
    "    args=args,\n",
    "    model=bert_model,\n",
    "    train_dataset=boolq_enc['train'],\n",
    "    eval_dataset=boolq_enc['validation'],\n",
    "    tokenizer=bert_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_patch_coordinator(mpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1636' max='818' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [818/818 09:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6939059495925903,\n",
       " 'eval_accuracy': 0.6214067278287462,\n",
       " 'eval_threshold': 0.5,\n",
       " 'eval_ampere_temperature': 20.0,\n",
       " 'eval_regu_lambda': 0.0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='7071' max='7071' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7071/7071 25:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Ampere Temperature</th>\n",
       "      <th>Regu Lambda</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.617738</td>\n",
       "      <td>0.599703</td>\n",
       "      <td>0.726300</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.942556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.530716</td>\n",
       "      <td>0.891712</td>\n",
       "      <td>0.766972</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.331953</td>\n",
       "      <td>1.161491</td>\n",
       "      <td>0.759633</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7071, training_loss=0.4934706015931449)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"models/bert-base-uncased-finetuned-boolq-pruned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_pruning.inference_model_patcher import optimize_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed heads 0, total_heads=144, percentage removed=0.0\n",
      "bert.encoder.layer.0.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.0.output.dense, sparsity = 0.00\n",
      "bert.encoder.layer.1.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.1.output.dense, sparsity = 0.00\n",
      "bert.encoder.layer.2.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.2.output.dense, sparsity = 0.00\n",
      "bert.encoder.layer.3.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.3.output.dense, sparsity = 0.00\n",
      "bert.encoder.layer.4.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.4.output.dense, sparsity = 0.00\n",
      "bert.encoder.layer.5.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.5.output.dense, sparsity = 0.00\n",
      "bert.encoder.layer.6.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.6.output.dense, sparsity = 0.00\n",
      "bert.encoder.layer.7.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.7.output.dense, sparsity = 0.00\n",
      "bert.encoder.layer.8.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.8.output.dense, sparsity = 0.00\n",
      "bert.encoder.layer.9.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.9.output.dense, sparsity = 0.00\n",
      "bert.encoder.layer.10.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.10.output.dense, sparsity = 0.00\n",
      "bert.encoder.layer.11.intermediate.dense, sparsity = 0.00\n",
      "bert.encoder.layer.11.output.dense, sparsity = 0.00\n"
     ]
    }
   ],
   "source": [
    "pruned_model = optimize_model(trainer.model, \"dense\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency (ms) - 416.89 +\\- 83.08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time_avg_ms': 416.89285065978765, 'time_std_ms': 83.08497178819044}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_latency(pruned_model.to(\"cpu\"), bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySparseXP(SparseXP, MyXP):\n",
    "    ARGUMENTS = {\n",
    "        \"model\": ModelArguments,\n",
    "        \"data\": DataTrainingArguments,\n",
    "        \"training\": XPTrainingArguments,\n",
    "        \"sparse\": SparseTrainingArguments,\n",
    "    }\n",
    "    MY_TRAINER_CLASS = MyTrainer\n",
    "#     SHORT_NAMER = MySparseShortNamer\n",
    "    CONSTRUCTOR = AutoModelForSequenceClassification\n",
    "    LOGIT_NAMES = [\"logits\"]\n",
    "\n",
    "    def __init__(self, params):\n",
    "        MyXP.__init__(self, params)\n",
    "        SparseXP.__init__(self)\n",
    "\n",
    "    def create_trainer(self, *args, **kwargs):\n",
    "        super().create_trainer(*args, **kwargs)\n",
    "        SparseXP.setup_trainer(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  \"model_name_or_path\": \"bert-base-uncased\",\n",
    "  \"dataset_name\": \"super_glue\",\n",
    "  \"dataset_cache_dir\": \"dataset_cache_dir\",\n",
    "  \"do_train\": 1,\n",
    "  \"do_eval\": 1,\n",
    "  \"per_device_train_batch_size\": 32,\n",
    "  \"per_device_eval_batch_size\": 128,\n",
    "  \"max_seq_length\": 128,\n",
    "  \"doc_stride\": 128,\n",
    "  \"num_train_epochs\": 12,\n",
    "  \"logging_steps\": 250,\n",
    "  \"save_steps\": 5000,\n",
    "  \"eval_steps\": 5000,\n",
    "  \"save_total_limit\": 50,\n",
    "  \"seed\": 17,\n",
    "  \"evaluation_strategy\": \"steps\",\n",
    "  \"learning_rate\": 3e-5,\n",
    "  \"mask_scores_learning_rate\": 1e-2,\n",
    "  \"output_dir\": \"output/mnli_test2/\",\n",
    "  \"logging_dir\": \"output/mnli_test2/\",\n",
    "  \"overwrite_cache\": 0,\n",
    "  \"overwrite_output_dir\": 1,\n",
    "  \"warmup_steps\": 12000,\n",
    "  \"initial_warmup\": 1,\n",
    "  \"final_warmup\": 4,\n",
    "  \"initial_threshold\": 0,\n",
    "  \"final_threshold\": 0.1,\n",
    "  \"dense_pruning_method\": \"sigmoied_threshold:1d_alt\",\n",
    "  \"dense_block_rows\":1,\n",
    "  \"dense_block_cols\":1,\n",
    "  \"dense_lambda\":1.0,\n",
    "  \"attention_pruning_method\": \"sigmoied_threshold\",\n",
    "  \"attention_block_rows\":32,\n",
    "  \"attention_block_cols\":32,\n",
    "  \"attention_lambda\":1.0,\n",
    "  \"ampere_pruning_method\": \"disabled\",\n",
    "  \"mask_init\": \"constant\",\n",
    "  \"mask_scale\": 0.0,\n",
    "  \"regularization\": \"l1\",\n",
    "  \"regularization_final_lambda\": 20,\n",
    "  \"distil_teacher_name_or_path\":\"aloxatel/bert-base-mnli\",\n",
    "  \"distil_alpha_ce\": 0.1,\n",
    "  \"distil_alpha_teacher\": 0.90,\n",
    "  \"attention_output_with_dense\": 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MySparseXP(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/08/2021 20:44:45 - WARNING - nn_pruning.examples.xp -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/08/2021 20:44:45 - INFO - nn_pruning.examples.xp -   Training/evaluation parameters\n",
      "03/08/2021 20:44:45 - INFO - nn_pruning.examples.xp -     Model: ModelArguments(model_name_or_path='bert-base-uncased', config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True)\n",
      "03/08/2021 20:44:45 - INFO - nn_pruning.examples.xp -     Data: DataTrainingArguments(dataset_name='super_glue', dataset_config_name=None, train_file=None, validation_file=None, overwrite_cache=0, dataset_cache_dir='dataset_cache_dir', preprocessing_num_workers=None, max_seq_length=128, pad_to_max_length=True, doc_stride=128)\n",
      "03/08/2021 20:44:45 - INFO - nn_pruning.examples.xp -     Training: XPTrainingArguments(output_dir='output/mnli_test2/', overwrite_output_dir=1, do_train=1, do_eval=1, do_predict=False, model_parallel=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=128, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=12, max_steps=-1, warmup_steps=12000, logging_dir='output/mnli_test2/', logging_first_step=False, logging_steps=250, save_steps=5000, save_total_limit=50, no_cuda=False, seed=17, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=5000, dataloader_num_workers=0, past_index=-1, run_name='output/mnli_test2/', disable_tqdm=True, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, fp16_backend='auto', sharded_ddp=False, optimize_model_before_eval='disabled')\n",
      "03/08/2021 20:44:45 - INFO - nn_pruning.examples.xp -     Sparse: SparseTrainingArguments(mask_scores_learning_rate=0.01, dense_pruning_method='sigmoied_threshold:1d_alt', attention_pruning_method='sigmoied_threshold', ampere_pruning_method='disabled', attention_output_with_dense=0, bias_mask=True, mask_init='constant', mask_scale=0.0, dense_block_rows=1, dense_block_cols=1, attention_block_rows=32, attention_block_cols=32, initial_threshold=0, final_threshold=0.1, initial_warmup=1, final_warmup=4, initial_ampere_temperature=0.0, final_ampere_temperature=20.0, regularization='l1', regularization_final_lambda=20, attention_lambda=1.0, dense_lambda=1.0, distil_teacher_name_or_path='aloxatel/bert-base-mnli', distil_alpha_ce=0.1, distil_alpha_teacher=0.9, distil_temperature=2.0, final_finetune=False, layer_norm_patch=False, gelu_patch=False)\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Implement in subclass",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-ccbc81af12e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/storage/git/nn_pruning/nn_pruning/examples/xp.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/git/nn_pruning/nn_pruning/examples/xp.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Implement in subclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Implement in subclass"
     ]
    }
   ],
   "source": [
    "trainer.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MySparseXP' object has no attribute 'trainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f245b31d31e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/storage/git/nn_pruning/nn_pruning/examples/xp.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*** Evaluate ***\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MySparseXP' object has no attribute 'trainer'"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoolSparseXP(SparseXP, GlueXP):\n",
    "    ARGUMENTS = {\n",
    "        \"model\": ModelArguments,\n",
    "        \"data\": GlueDataTrainingArguments,\n",
    "        \"training\": XPTrainingArguments,\n",
    "        \"sparse\": SparseTrainingArguments,\n",
    "    }\n",
    "    GLUE_TRAINER_CLASS = GlueSparseTrainer\n",
    "    SHORT_NAMER = SparseGlueShortNamer\n",
    "    CONSTRUCTOR = AutoModelForSequenceClassification\n",
    "    LOGIT_NAMES = [\"logits\"]\n",
    "\n",
    "    def __init__(self, params):\n",
    "        GlueXP.__init__(self, params)\n",
    "        SparseXP.__init__(self)\n",
    "\n",
    "    def create_trainer(self, *args, **kwargs):\n",
    "        super().create_trainer(*args, **kwargs)\n",
    "        SparseXP.setup_trainer(self)\n",
    "\n",
    "    @classmethod\n",
    "    def final_finetune(cls, src_path, dest_path, task, teacher):\n",
    "        param_dict = {\n",
    "            \"model_name_or_path\": src_path,\n",
    "            \"task_name\": task,\n",
    "            \"dataset_cache_dir\": \"dataset_cache_dir\",\n",
    "            \"do_train\": 1,\n",
    "            \"do_eval\": 1,\n",
    "            \"per_device_train_batch_size\": 32,\n",
    "            \"per_device_eval_batch_size\": 128,\n",
    "            \"max_seq_length\": 128,\n",
    "            \"doc_stride\": 128,\n",
    "            \"num_train_epochs\": 6,\n",
    "            \"logging_steps\": 250,\n",
    "            \"save_steps\": 5000,\n",
    "            \"eval_steps\": 5000,\n",
    "            \"save_total_limit\": 50,\n",
    "            \"seed\": 17,\n",
    "            \"evaluation_strategy\": \"steps\",\n",
    "            \"learning_rate\": 3e-5,\n",
    "            \"output_dir\": dest_path,\n",
    "            \"logging_dir\": dest_path,\n",
    "            \"overwrite_cache\": 0,\n",
    "            \"overwrite_output_dir\": 1,\n",
    "            \"warmup_steps\": 10,\n",
    "            \"initial_warmup\": 0,\n",
    "            \"final_warmup\": 0,\n",
    "            \"mask_init\": \"constant\",\n",
    "            \"mask_scale\": 0.0,\n",
    "            \"regularization\": \"\",\n",
    "            \"regularization_final_lambda\": 0,\n",
    "            \"distil_teacher_name_or_path\":teacher,\n",
    "            \"distil_alpha_ce\": 0.1,\n",
    "            \"distil_alpha_teacher\": 0.90,\n",
    "            \"attention_output_with_dense\": 0,\n",
    "            \"final_finetune\": 1,\n",
    "        }\n",
    "\n",
    "\n",
    "        glue = cls(param_dict)\n",
    "        glue.run()\n",
    "\n",
    "        cls.fix_last_checkpoint_bug(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_args = SparseTrainingArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = AutoModelForSequenceClassification.from_pretrained(bert_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "learning_rate = 2e-5\n",
    "num_train_epochs = 3\n",
    "logging_steps = len(boolq_enc['train']) // batch_size\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='checkpoints',\n",
    "    evaluation_strategy='epoch',\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=logging_steps,\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "pruning_trainer = PruningTrainer(\n",
    "    sparse_args=sparse_args,\n",
    "    args=args,\n",
    "    model= bert_model,\n",
    "    train_dataset=boolq_enc['train'],\n",
    "    eval_dataset=boolq_enc['validation'],\n",
    "    tokenizer=bert_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PruningTrainer' object has no attribute 'patch_coordinator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3aa219393839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpruning_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/storage/git/nn_pruning/nn_pruning/sparse_trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"eval_\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/git/nn_pruning/nn_pruning/sparse_trainer.py\u001b[0m in \u001b[0;36mschedule_threshold\u001b[0;34m(self, training)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mschedule_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_coordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PruningTrainer' object has no attribute 'patch_coordinator'"
     ]
    }
   ],
   "source": [
    "pruning_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'compute_loss',\n",
       " 'create_optimizer',\n",
       " 'create_optimizer_and_scheduler',\n",
       " 'create_scheduler',\n",
       " 'evaluate',\n",
       " 'log',\n",
       " 'schedule_threshold',\n",
       " 'set_patch_coordinator',\n",
       " 'training_step']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(SparseTrainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformerlab",
   "language": "python",
   "name": "transformerlab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
